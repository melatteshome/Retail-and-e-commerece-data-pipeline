version: "3.9"

networks:
  bigdata-net: {}

services:
  kafka:
    image: bitnami/kafka:latest
    container_name: kafka
    environment:
      KAFKA_ENABLE_KRAFT: "yes"                     # ➊ new mode
      KAFKA_CFG_NODE_ID: 1                          # ➋ unique int
      KAFKA_CFG_PROCESS_ROLES: controller,broker    # ➌ declare role(s)
      KAFKA_CFG_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CFG_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093
      KAFKA_CFG_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_CFG_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      ALLOW_PLAINTEXT_LISTENER: "yes"
    ports:
      - "9092:9092"


  # ---------- Spark cluster ----------
  spark-master:
    image: bitnami/spark:latest
    container_name: spark-master
    environment:
      SPARK_MODE: master
      SPARK_MASTER_HOST: spark-master
    ports:
      - "8080:8080"   # Web UI
      - "7077:7077"   # RPC
    volumes:
      - ./spark/apps:/opt/spark-apps

  spark-worker-1:
    image: bitnami/spark:latest
    container_name: spark-worker-1
    depends_on: [spark-master]
    environment:
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://spark-master:7077
    ports: ["8081:8081"]

  spark-worker-2:
    image: bitnami/spark:latest
    container_name: spark-worker-2
    depends_on: [spark-master]
    environment:
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://spark-master:7077
    ports: ["8082:8081"]

  # ---------- Databend (Meta + Query) ----------
  databend-meta:
    image: datafuselabs/databend-meta:latest
    container_name: databend-meta
    command: >
      /databend-meta
      --single
      --grpc-api-address=0.0.0.0:9191
      --admin-api-address=0.0.0.0:28101
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:28101/v1/health"]
      interval: 5s
      retries: 10
    environment:
      - RUST_BACKTRACE=1
    volumes:
      - ./databend-meta:/data

  databend-query:
    image: datafuselabs/databend-query:latest
    container_name: databend-query
    depends_on: [databend-meta]
    environment:
      QUERY_DEFAULT_USER: root
      QUERY_DEFAULT_PASSWORD: root
      META_ENDPOINTS: databend-meta:9191
    ports:
      - "9090:9090"   # Flight/Arrow
      - "3307:3307"   # MySQL wire-protocol
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7070/metrics"]
      interval: 10s
      retries: 10
    volumes:
      - ./databend-query:/var/lib/databend




  # ────────── Hadoop ──────────
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    hostname: namenode.local
    environment:
      - CLUSTER_NAME=hive-cluster
      - CORE_CONF_fs_defaultFS=hdfs://namenode.local:8020
    ports:
      - "9870:9870"     # NameNode web UI
      - "8020:8020"     # HDFS RPC
    volumes:
      - namenode-data:/hadoop/dfs/name
    networks: [bigdata-net]

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    hostname: datanode.local
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode.local:8020
    depends_on: [namenode]
    ports:
      - "9864:9864"     # DataNode web UI
    volumes:
      - datanode-data:/hadoop/dfs/data
    networks: [bigdata-net]

  # ────────── Hive Metastore backend ──────────
  metastore-db:
    image: postgres:14
    container_name: metastore-db
    hostname: metastore-db.local
    environment:
      POSTGRES_DB: metastore
      POSTGRES_USER: hive
      POSTGRES_PASSWORD: hivepassword
    volumes:
      - metastore-db-data:/var/lib/postgresql/data
    networks: [bigdata-net]

  # ────────── Hive services ──────────
  metastore:
    image: apache/hive:4.0.0
    container_name: hive-metastore
    hostname: metastore.local
    environment:
      SERVICE_NAME: metastore
      HIVE_METASTORE_USER: hive
      HIVE_METASTORE_PASSWORD: hivepassword
      HIVE_METASTORE_DB_HOSTNAME: metastore-db.local
      CORE_CONF_fs_defaultFS: hdfs://namenode.local:8020
    depends_on: [namenode, datanode, metastore-db]
    ports:
      - "9083:9083"     # Thrift metastore
    networks: [bigdata-net]

  hiveserver2:
    image: apache/hive:4.0.0
    container_name: hiveserver2
    hostname: hiveserver2.local
    environment:
      SERVICE_NAME: hiveserver2
      HIVE_METASTOREURIS: thrift://metastore.local:9083
      CORE_CONF_fs_defaultFS: hdfs://namenode.local:8020
    depends_on: [metastore]
    ports:
      - "10000:10000"   # JDBC/Beeline
      - "10002:10002"   # Web UI
    networks: [bigdata-net]

volumes:
  namenode-data:
  datanode-data:
  metastore-db-data:


